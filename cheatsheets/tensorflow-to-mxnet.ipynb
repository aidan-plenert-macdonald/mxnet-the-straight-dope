{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So you want to convert Tensorflow to MxNet, eh? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try parsing the API's and generate a mapping between the two. This might take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import tensorflow as tf\n",
    "import pkgutil, types, pprint\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "def doc_dump(base, docs={}):\n",
    "    try:\n",
    "        for a in dir(eval(base)):\n",
    "            if isinstance(eval(base).__dict__.get(a), types.FunctionType):\n",
    "                doc = eval(base).__dict__.get(a).__doc__\n",
    "                docs[base + '.' + a] = base + '.' + a + (doc if doc else '')\n",
    "        for importer, modname, ispkg in pkgutil.walk_packages(path=eval(base).__path__,\n",
    "                                                              prefix=base + '.',\n",
    "                                                              onerror=lambda e: None):\n",
    "            docs = doc_dump(modname, docs)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return docs\n",
    "        \n",
    "tf_docs = doc_dump('tf', {})\n",
    "mx_docs = doc_dump('mx', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SAMPLE = -1\n",
    "tf_labels, tf_values = zip(*list(tf_docs.items())[:SUB_SAMPLE])\n",
    "mx_labels, mx_values = zip(*list(mx_docs.items())[:SUB_SAMPLE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_UNITS = 100\n",
    "LAYERS = 1\n",
    "BATCH_SIZE = 1\n",
    "INPUT_SIZE = 1\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg as s_linalg\n",
    "\n",
    "W = sparse.rand(HIDDEN_UNITS, HIDDEN_UNITS, density=0.1)\n",
    "W = W*np.real(0.9/max(s_linalg.eigs(W)[0]))\n",
    "U = 0.8*sparse.rand(HIDDEN_UNITS, INPUT_SIZE, density=0.1)\n",
    "\n",
    "tf_states = []\n",
    "for v in tf_values:\n",
    "    h = np.zeros((HIDDEN_UNITS, 1))\n",
    "    for c in v:\n",
    "        h = np.tanh(W.dot(h) + U*ord(c))\n",
    "    tf_states.append(mx.nd.array(h))\n",
    "    \n",
    "mx_states = []\n",
    "for v in mx_values:\n",
    "    h = np.zeros((HIDDEN_UNITS, 1))\n",
    "    for c in v:\n",
    "        h = np.tanh(W.dot(h) + U*ord(c))\n",
    "    mx_states.append(mx.nd.array(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[16:52:49] src/pass/gradient.cc:187: Operator _copyto is non-differentiable because it didn't register FGradient attribute.\n\nStack trace returned 10 entries:\n[bt] (0) 0   libmxnet.so                         0x000000010e316408 _ZN4dmlc15LogMessageFatalD2Ev + 40\n[bt] (1) 1   libmxnet.so                         0x000000010faac311 _ZN4nnvm4pass12_GLOBAL__N_18GradientENS_5GraphE + 15889\n[bt] (2) 2   libmxnet.so                         0x000000010f278ee1 _ZNSt3__128__invoke_void_return_wrapperIN4nnvm5GraphEE6__callIJRPFS2_S2_ES2_EEES2_DpOT_ + 209\n[bt] (3) 3   libmxnet.so                         0x000000010f278dd2 _ZNSt3__110__function6__funcIPFN4nnvm5GraphES3_ENS_9allocatorIS5_EES4_EclEOS3_ + 18\n[bt] (4) 4   libmxnet.so                         0x000000010fa9b03b _ZN4nnvm11ApplyPassesENS_5GraphERKNSt3__16vectorINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS6_IS8_EEEE + 795\n[bt] (5) 5   libmxnet.so                         0x000000010f0dfddb _ZN4nnvm9ApplyPassENS_5GraphERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE + 187\n[bt] (6) 6   libmxnet.so                         0x000000010f10bd32 _ZN4nnvm4pass8GradientENS_5GraphENSt3__16vectorINS_9NodeEntryENS2_9allocatorIS4_EEEES7_S7_NS2_8functionIFS4_OS7_EEENS8_IFiRKNS_4NodeEEEENS8_IFS4_RKS4_SI_EEENS3_IPKNS_2OpENS5_ISN_EEEENS2_12basic_stringIcNS2_11char_traitsIcEENS5_IcEEEE + 2130\n[bt] (7) 7   libmxnet.so                         0x000000010f14fdc4 _ZN5mxnet10Imperative8BackwardERKNSt3__16vectorIPNS_7NDArrayENS1_9allocatorIS4_EEEES9_S9_bbb + 3860\n[bt] (8) 8   libmxnet.so                         0x000000010f0d9e9d MXAutogradBackwardEx + 893\n[bt] (9) 9   _ctypes.cpython-36m-darwin.so       0x000000010d1cc42f ffi_call_unix64 + 79\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-14981406278a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [16:52:49] src/pass/gradient.cc:187: Operator _copyto is non-differentiable because it didn't register FGradient attribute.\n\nStack trace returned 10 entries:\n[bt] (0) 0   libmxnet.so                         0x000000010e316408 _ZN4dmlc15LogMessageFatalD2Ev + 40\n[bt] (1) 1   libmxnet.so                         0x000000010faac311 _ZN4nnvm4pass12_GLOBAL__N_18GradientENS_5GraphE + 15889\n[bt] (2) 2   libmxnet.so                         0x000000010f278ee1 _ZNSt3__128__invoke_void_return_wrapperIN4nnvm5GraphEE6__callIJRPFS2_S2_ES2_EEES2_DpOT_ + 209\n[bt] (3) 3   libmxnet.so                         0x000000010f278dd2 _ZNSt3__110__function6__funcIPFN4nnvm5GraphES3_ENS_9allocatorIS5_EES4_EclEOS3_ + 18\n[bt] (4) 4   libmxnet.so                         0x000000010fa9b03b _ZN4nnvm11ApplyPassesENS_5GraphERKNSt3__16vectorINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS6_IS8_EEEE + 795\n[bt] (5) 5   libmxnet.so                         0x000000010f0dfddb _ZN4nnvm9ApplyPassENS_5GraphERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE + 187\n[bt] (6) 6   libmxnet.so                         0x000000010f10bd32 _ZN4nnvm4pass8GradientENS_5GraphENSt3__16vectorINS_9NodeEntryENS2_9allocatorIS4_EEEES7_S7_NS2_8functionIFS4_OS7_EEENS8_IFiRKNS_4NodeEEEENS8_IFS4_RKS4_SI_EEENS3_IPKNS_2OpENS5_ISN_EEEENS2_12basic_stringIcNS2_11char_traitsIcEENS5_IcEEEE + 2130\n[bt] (7) 7   libmxnet.so                         0x000000010f14fdc4 _ZN5mxnet10Imperative8BackwardERKNSt3__16vectorIPNS_7NDArrayENS1_9allocatorIS4_EEEES9_S9_bbb + 3860\n[bt] (8) 8   libmxnet.so                         0x000000010f0d9e9d MXAutogradBackwardEx + 893\n[bt] (9) 9   _ctypes.cpython-36m-darwin.so       0x000000010d1cc42f ffi_call_unix64 + 79\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "net = mx.gluon.nn.Dense(HIDDEN_UNITS)\n",
    "ctx = mx.cpu()\n",
    "net.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "\n",
    "trainer = mx.gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})\n",
    "l2loss = mx.gluon.loss.L2Loss()\n",
    "\n",
    "data = list(enumerate(tf_states + mx_states))\n",
    "\n",
    "for epoch in range(100):\n",
    "    avg_loss = 0.0\n",
    "    with mx.autograd.record():\n",
    "        loss = 0.0\n",
    "        for k in range(40):\n",
    "            (i, x), (j, y) = random.choice(data), random.choice(data)\n",
    "            # Just compute loss on last output\n",
    "            if i == j:\n",
    "                loss = loss - l2loss(net(mx.nd.array(x)), net(mx.nd.array(y)))\n",
    "            else:\n",
    "                loss = loss + l2loss(net(mx.nd.array(x)), net(mx.nd.array(y)))\n",
    "        loss.backward()\n",
    "    trainer.step(BATCH_SIZE)\n",
    "    avg_loss += mx.nd.mean(loss).asscalar()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(epoch, avg_loss/(len(tf_values) + len(mx_values))**2)\n",
    "        for i in np.random.randint(len(tf_values), size=10):\n",
    "            losses = []\n",
    "            for j in range(len(mx_values)):\n",
    "                losses.append((l2loss(net(x).reshape((1, -1)), net(y).reshape((1, -1))).asscalar(), j))\n",
    "                losses = sorted(losses)[:3]\n",
    "            print('\\t', tf_labels[i], ' ==> ', [mx_labels[j] for l, j in losses])\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
